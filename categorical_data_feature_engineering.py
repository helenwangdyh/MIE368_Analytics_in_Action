# -*- coding: utf-8 -*-
"""Categorical_Data_Feature_Engineering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C6gffvTl1RGiD3tYoXXa1iW7iXnQrkW7
"""

from google.colab import drive
drive.mount('/content/drive')

dataset_dir = "/content/drive/My Drive/MIE368 Project/clean_data.csv"

import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns

"""### Categorical Data Treatment: Clustering Method"""

# load clean data
dataset = pd.read_csv(dataset_dir)
dataset.head()

cat_analysis = dataset[['business_id', 'business_name', 'business_categories']]
cat_analysis = cat_analysis.dropna().drop_duplicates()
cat_analysis['cat_tags'] = cat_analysis.business_categories.apply(lambda x: len(x.split(',')))
plt.hist(cat_analysis.cat_tags)
plt.xlabel('number of tags used for the business')
plt.show()
cat_analysis.head()

# Find unique categories again with Food related entry only

temp_cat = dataset.business_categories
temp_cat = temp_cat.dropna().unique()
print('Total number of entries with business_categories data: {}'.format(len(temp_cat)))
print('sample entries for business_categories data:')
print(temp_cat[:5])
all_cat = []
for row in temp_cat:
  temp_row = row.split(',')
  for entry in temp_row:
    all_cat.append(entry)

# Observed entries with ' Restaurants', need to remove ' ' before words
for i, cat in enumerate(all_cat):
  if cat[0] == ' ':
    all_cat[i] = cat[1:]

all_cat_count = pd.Series(all_cat).value_counts()
all_cat = pd.Series(all_cat).unique()

dt_treat_cat = dataset.copy()
features = ["business_id","business_name",
            "business_stars","business_review_count",
            "business_categories"]
dt_treat_cat = dt_treat_cat[features]

for cat in all_cat:
  dt_treat_cat[cat] = np.where(dt_treat_cat.business_categories.str.find(cat) != -1, 1, 0)
  print('Categories: {}, Number of Entries: {}'.format(cat, dt_treat_cat[cat].sum()))

dt_treat_cat.head()

dt_treat_cat_unique_bus = dt_treat_cat.drop_duplicates()
print(dt_treat_cat.business_id.unique().shape)
dt_treat_cat_unique_bus.head()

base_corrs = dt_treat_cat_unique_bus.corr().business_stars.drop(index='business_stars')

pd.DataFrame(base_corrs).sort_values(by='business_stars', ascending=False).T

from sklearn.cluster import FeatureAgglomeration

# Define clustering model
n_clusters = 15
mdk_FeatureAgg = FeatureAgglomeration(n_clusters=n_clusters)

def run_model(mdl, x_train):

  # Fit the model to the training set
  mdl.fit(x_train)#[non_binary_columns])

  # Get cluster assignments for each datapoint
  clK = mdl.labels_
  
  return clK

features = ["business_id", "business_name", "business_categories", "business_stars", "business_review_count"]
#"Restaurants", "Food", "Bars", "Coffee & Tea"

dt_treat_cat_unique_bus_train = dt_treat_cat_unique_bus.drop(features, axis=1)
clK = run_model(mdk_FeatureAgg, dt_treat_cat_unique_bus_train)

cat_train_count = pd.DataFrame(dt_treat_cat_unique_bus_train.sum(), columns = ["count"])
cat_train_count = cat_train_count.sort_values(by='count',ascending=False).T
plt.hist(cat_train_count)
plt.xlabel('number of business in category')
plt.show()

plt.hist(cat_train_count.iloc[:,5:])
plt.xlabel('number of business in category')
plt.show()

cat_train_count

pd.DataFrame(dt_treat_cat_unique_bus_train.corr()['Mediterranean'], columns=['Mediterranean']).sort_values(by='Mediterranean',ascending=False).head(20)

# Define clustering model
n_clusters = 20
mdk_FeatureAgg = FeatureAgglomeration(n_clusters=n_clusters)

clK = run_model(mdk_FeatureAgg, dt_treat_cat_unique_bus_train)
result = pd.DataFrame(zip(np.array(dt_treat_cat_unique_bus_train.columns), clK), columns=['Features','Cluster'])
for i in range(n_clusters):
  print("Cluster {}".format(i))
  print(np.array(result[result['Cluster']==i].Features))

dt_treat_cat_unique_final = dt_treat_cat_unique_bus.copy()

features_final = []

for i in range(n_clusters):
  if i not in [1,2]:
    features = np.array(result[result['Cluster']==i].Features)
    if len(features) > 1:
      dt_treat_cat_unique_final[' '.join(features)] = np.where(dt_treat_cat_unique_final[features].sum(axis=1)>0, 1, 0)
      dt_treat_cat_unique_bus_train[' '.join(features)] = np.where(dt_treat_cat_unique_bus_train[features].sum(axis=1)>0, 1, 0)
      dt_treat_cat_unique_final = dt_treat_cat_unique_final.drop(features, axis=1)
      dt_treat_cat_unique_bus_train = dt_treat_cat_unique_bus_train.drop(features, axis=1)
      features_final.append(' '.join(features))
    else:
      features_final.append(features[0])
dt_treat_cat_unique_final

cat_train_count = pd.DataFrame(dt_treat_cat_unique_bus_train.sum(), columns = ["count"])
cat_train_count = cat_train_count.sort_values(by='count',ascending=False).T
cat_train_count

features_final.append('Nightlife')

features_final.remove('Food')
features_final

dt_treat_cat_unique_final_2 = dt_treat_cat_unique_final.copy()
dt_treat_cat_unique_final_2[features_final].sum()

dt_treat_cat_unique_final_2[dt_treat_cat_unique_final_2[features_final]==1]

fig, ax = plt.subplots(6,3, figsize=(16, 12))
fig.subplots_adjust(bottom=0.4, top=1.5)
ax = ax.ravel()

for i, f in enumerate(features_final):
  stars = dt_treat_cat_unique_final_2[dt_treat_cat_unique_final_2[f]==1].business_stars.mean()
  print('Categories: {}, Stars: {}'.format(f, stars))
  dt_treat_cat_unique_final_2[dt_treat_cat_unique_final_2[f]==1].hist('business_stars', ax=ax[i], bins=5)
  ax[i].set_title('{}'.format(f))

fig, ax = plt.subplots(6,3, figsize=(16, 12))
fig.subplots_adjust(bottom=0.4, top=1.5)
ax = ax.ravel()

dt_treat_cat_unique_final_2['business_review_count_log'] = np.log(dt_treat_cat_unique_final_2['business_review_count'])

for i, f in enumerate(features_final):
  stars = dt_treat_cat_unique_final_2[dt_treat_cat_unique_final_2[f]==1].business_review_count.mean()
  print('Categories: {}, Stars: {}'.format(f, stars))
  dt_treat_cat_unique_final_2[dt_treat_cat_unique_final_2[f]==1].hist('business_review_count_log', ax=ax[i], bins=5)
  ax[i].set_title('{}'.format(f))

pd.DataFrame(dt_treat_cat_unique_bus_train.corr()[f], columns=[f]).sort_values(by=f,ascending=False).head(10)

dt_treat_cat_unique_final_2 = dt_treat_cat_unique_final.copy()
features_final_2 = []

for i, f in enumerate(features_final):
  print(f)
  temp_fs = [f]
  temp_corr = pd.DataFrame(dt_treat_cat_unique_bus_train.corr()[f], columns=[f]).sort_values(by=f,ascending=False).head(10)
  temp_corr_arry = np.array(temp_corr[temp_corr[f]>=0.15].index)
  if len(temp_corr_arry) > 0:
    for n_f in temp_corr_arry:
      if n_f not in features_final_2 and n_f != 'Bars' and n_f != 'Food':
        temp_fs.append(n_f)
    f = ' '.join(temp_fs)
    features_final_2.append(f)
    print(f)
    dt_treat_cat_unique_final_2[f] = np.where(dt_treat_cat_unique_final_2[temp_fs].sum(axis=1)>0, 1, 0)
    dt_treat_cat_unique_final_2 = dt_treat_cat_unique_final_2.drop(n_f, axis=1)
  else:
    features_final_2.append(f)

print(features_final_2)
dt_treat_cat_unique_final_2

# Clustering Function
def run_cat_cluster(mdl, x_train):

  # Fit the model to the training set
  mdl.fit(x_train)

  # Get cluster assignments for each datapoint
  clK = mdl.labels_
  
  #print result
  result = pd.DataFrame(zip(np.array(x_train.columns), clK), columns=['Features','Cluster'])
  for i in range(n_clusters):
    print("Cluster {}".format(i))
    print(np.array(result[result['Cluster']==i].Features))

  return clK, result

features = ["business_id", "business_name", "business_categories", "business_stars", "business_review_count"]
dt_treat_cat_train = dt_treat_cat.drop(features, axis=1)

# Define clustering model
n_clusters = 15
mdk_FeatureAgg = FeatureAgglomeration(n_clusters=n_clusters)

clK, result = run_cat_cluster(mdk_FeatureAgg, dt_treat_cat_train[np.array(cat_train_count.columns)[4:100]])

cat_train_count.sort_values(by='count',ascending=False).T

cat_train_count = cat_train_count.sort_values(by='count',ascending=False)
# Define clustering model: modelling for less frequent categories, join clustered features together.
n_clusters = 5
mdk_FeatureAgg = FeatureAgglomeration(n_clusters=n_clusters)
clK, result = run_cat_cluster(mdk_FeatureAgg, dt_treat_cat_train[np.array(cat_train_count[-60:].index)])

dt_treat_cat_train_2 = dt_treat_cat_train.copy()
dt_treat_cat_train_2['Russian Ukrainian'] = np.where(dt_treat_cat_train_2['Russian']+dt_treat_cat_train_2['Ukrainian']>=1, 1, 0)
dt_treat_cat_train_2['Whiskey Bars Scottish'] = np.where(dt_treat_cat_train_2['Whiskey Bars']+dt_treat_cat_train_2['Scottish']>=1, 1, 0)
dt_treat_cat_train_2 = dt_treat_cat_train_2.drop(['Russian','Ukrainian','Whiskey Bars','Scottish'], axis=1)
cat_train_count_2 = pd.DataFrame(dt_treat_cat_train_2.sum(), columns = ["count"]).sort_values(by=['count'], ascending=False)

n_clusters = 8
mdk_FeatureAgg = FeatureAgglomeration(n_clusters=n_clusters)
clK, result = run_cat_cluster(mdk_FeatureAgg, dt_treat_cat_train_2[np.array(cat_train_count_2[-90:].index)])

dt_treat_cat_train_3 = dt_treat_cat_train_2.copy()
dt_treat_cat_train_3['Argentine Peruvian'] = np.where(dt_treat_cat_train_3['Argentine']+dt_treat_cat_train_3['Peruvian']>=1, 1, 0)
dt_treat_cat_train_3['Kebab Donairs'] = np.where(dt_treat_cat_train_3['Kebab']+dt_treat_cat_train_3['Donairs']>=1, 1, 0)
dt_treat_cat_train_3['Pan Asian Singaporean'] = np.where(dt_treat_cat_train_3['Pan Asian']+dt_treat_cat_train_3['Singaporean']>=1, 1, 0)
dt_treat_cat_train_3 = dt_treat_cat_train_3.drop(['Argentine', 'Peruvian','Kebab','Donairs','Pan Asian', 'Singaporean' ], axis=1)
cat_train_count_3 = pd.DataFrame(dt_treat_cat_train_3.sum(), columns = ["count"]).sort_values(by=['count'], ascending=False)

n_clusters = 8
mdk_FeatureAgg = FeatureAgglomeration(n_clusters=n_clusters)
clK, result = run_cat_cluster(mdk_FeatureAgg, dt_treat_cat_train_3[np.array(cat_train_count_3[-100:].index)])

dt_treat_cat_train_4 = dt_treat_cat_train_3.copy()
dt_treat_cat_train_4['Hookah Bars Smokehouse'] = np.where(dt_treat_cat_train_4['Hookah Bars']+dt_treat_cat_train_4['Smokehouse']>=1, 1, 0)
dt_treat_cat_train_4['Cheese Shops Meat Shops Butcher'] = np.where(dt_treat_cat_train_4['Cheese Shops']+dt_treat_cat_train_4['Meat Shops']+dt_treat_cat_train_4['Butcher']>=1, 1, 0)
dt_treat_cat_train_4['Falafel Kebab Donairs Afghan'] = np.where(dt_treat_cat_train_4['Falafel']+dt_treat_cat_train_4['Kebab Donairs']+dt_treat_cat_train_4['Afghan']>=1, 1, 0)
dt_treat_cat_train_4 = dt_treat_cat_train_4.drop(['Hookah Bars', 'Smokehouse', 'Cheese Shops', 'Meat Shops', 'Butcher', 'Falafel', 'Kebab Donairs', 'Afghan'], axis=1)
cat_train_count_4 = pd.DataFrame(dt_treat_cat_train_4.sum(), columns = ["count"]).sort_values(by=['count'], ascending=False)

n_clusters = 10
mdk_FeatureAgg = FeatureAgglomeration(n_clusters=n_clusters)
clK, result = run_cat_cluster(mdk_FeatureAgg, dt_treat_cat_train_4[np.array(cat_train_count_4[-130:].index)])

dt_treat_cat_train_5 = dt_treat_cat_train_4.copy()
dt_treat_cat_train_5['Donuts Soul Food Belgian Waffles'] = np.where(dt_treat_cat_train_5[['Donuts','Soul Food','Belgian','Waffles']].sum(axis=1)>=1, 1, 0)
dt_treat_cat_train_5['Portuguese African Ethiopian'] = np.where(dt_treat_cat_train_5[['Portuguese', 'African', 'Ethiopian']].sum(axis=1)>=1, 1, 0)
dt_treat_cat_train_5['Food Stands Food Trucks Street Vendors'] = np.where(dt_treat_cat_train_5[['Food Stands', 'Food Trucks','Street Vendors']].sum(axis=1)>=1, 1, 0)
dt_treat_cat_train_5['Poke Hawaiian'] = np.where(dt_treat_cat_train_5[['Poke','Hawaiian']].sum(axis=1)>=1, 1, 0)
dt_treat_cat_train_5['Turkish German'] = np.where(dt_treat_cat_train_5[['Turkish', 'German']].sum(axis=1)>=1, 1, 0)
dt_treat_cat_train_5['Patisserie/Cake Shop Macarons'] = np.where(dt_treat_cat_train_5[['Patisserie/Cake Shop', 'Macarons']].sum(axis=1)>=1, 1, 0)
dt_treat_cat_train_5 = dt_treat_cat_train_5.drop(['Donuts','Soul Food','Belgian','Waffles','Portuguese','African','Ethiopian','Food Stands','Food Trucks',\
                                                  'Street Vendors','Poke','Hawaiian','Turkish','German','Patisserie/Cake Shop', 'Macarons'], axis=1)
cat_train_count_5 = pd.DataFrame(dt_treat_cat_train_5.sum(), columns = ["count"]).sort_values(by=['count'], ascending=False)

cat_train_count_5[-150:-90].T

n_clusters = 8
mdk_FeatureAgg = FeatureAgglomeration(n_clusters=n_clusters)
clK, result = run_cat_cluster(mdk_FeatureAgg, dt_treat_cat_train_5[np.array(cat_train_count_5[-150:-40].index)])

dt_treat_cat_train_6 = dt_treat_cat_train_5.copy()
dt_treat_cat_train_6['Sports Bars Chicken Wings'] = np.where(dt_treat_cat_train_5[['Sports Bars','Chicken Wings']].sum(axis=1)>=1, 1, 0)
dt_treat_cat_train_6['Pakistani Halal'] = np.where(dt_treat_cat_train_5[['Pakistani','Halal']].sum(axis=1)>=1, 1, 0)
dt_treat_cat_train_6 = dt_treat_cat_train_6.drop(['Sports Bars','Chicken Wings', 'Pakistani','Halal'], axis=1)
cat_train_count_6 = pd.DataFrame(dt_treat_cat_train_6.sum(), columns = ["count"]).sort_values(by=['count'], ascending=False)

cat_train_count_6.shape

n_clusters = 6
mdk_FeatureAgg = FeatureAgglomeration(n_clusters=n_clusters)
clK, result = run_cat_cluster(mdk_FeatureAgg, dt_treat_cat_train_6[np.array(cat_train_count_6[-160:-80].index)])

dt_treat_cat_train_7 = dt_treat_cat_train_6.copy()
dt_treat_cat_train_7['Cocktail Bars Wine Bars Tapas Bars Wine & Spirits Gastropubs'] = np.where(dt_treat_cat_train_7[['Cocktail Bars','Wine Bars','Tapas Bars','Wine & Spirits','Gastropubs']].sum(axis=1)>=1, 1, 0)
dt_treat_cat_train_7['Ramen Noodles'] = np.where(dt_treat_cat_train_7[['Ramen','Noodles']].sum(axis=1)>=1, 1, 0)
dt_treat_cat_train_7['Vegan Salad Gluten-Free'] = np.where(dt_treat_cat_train_7[['Vegan', 'Salad', 'Gluten-Free']].sum(axis=1)>=1, 1, 0)
dt_treat_cat_train_7 = dt_treat_cat_train_7.drop(['Cocktail Bars','Wine Bars','Tapas Bars','Wine & Spirits','Gastropubs','Ramen','Noodles','Vegan', 'Salad', 'Gluten-Free'], axis=1)
cat_train_count_7 = pd.DataFrame(dt_treat_cat_train_7.sum(), columns = ["count"]).sort_values(by=['count'], ascending=False)

cat_train_count_7.T

n_clusters = 15
mdk_FeatureAgg = FeatureAgglomeration(n_clusters=n_clusters)
clK, result = run_cat_cluster(mdk_FeatureAgg, dt_treat_cat_train_7[np.array(cat_train_count_7[5:100].index)])

from sklearn.cluster import AgglomerativeClustering
dt_treat_cat_unique_bus_train_agg = dt_treat_cat_unique_bus_train.copy()

# Define clustering model
n_clusters = 20
mdk_Agg = AgglomerativeClustering(n_clusters=n_clusters)

def run_model(mdl, x_train):

  # Fit the model to the training set
  mdl.fit(x_train)#[non_binary_columns])

  # Get cluster assignments for each datapoint
  clK = mdl.labels_
  
  return clK

dt_treat_cat_unique_bus_train_agg["cluster"] = run_model(mdk_Agg, dt_treat_cat_unique_bus_train_agg)

pd.DataFrame(dt_treat_cat_unique_bus_train_agg[dt_treat_cat_unique_bus_train_agg["cluster"]==2].sum()).sort_values(by=0, ascending=False).head(20)